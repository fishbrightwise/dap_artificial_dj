{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce3ebc3",
   "metadata": {},
   "source": [
    "# Input your data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df87588",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install sklearn\n",
    "# %pip install -U scikit-learn\n",
    "# %pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3724bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"data/tracks.csv\")\n",
    "\n",
    "# Creating the dataframe\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API Authentication Information\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "#weilin's api key\n",
    "client_id = '169bbab461424df7a16d00fbdb3201ec'\n",
    "client_secret = '19fb464d5e34444aa5faa4613d35f6b6'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd03637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a new feature that comprises of Song Name and Artist.\n",
    "df[\"song_name_artist\"] = df[\"name\"] + df[\"artists\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['release_date'].str.extract(r'(\\d{4})').astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b15f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing all duplicate songs-artist pairs. Meaning that there won't be 2 of the same song sung by the same artist.\n",
    "print(df.shape)\n",
    "df.drop_duplicates(subset=[\"song_name_artist\"], keep='first', inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589dc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to keep songs published 2000* and later.\n",
    "df = df[df[\"year\"] >= 2000]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da750b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_null = df.copy()\n",
    "\n",
    "df_fill_null['name'] = df.apply(\n",
    "    lambda row: sp.track(f\"spotify:track:{row['id']}\")['name'] if pd.isnull(row['name']) else row['name'], axis=1\n",
    ")\n",
    "\n",
    "df_fill_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9232b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_null['first_artist'] = df_fill_null.apply(\n",
    "    lambda row: row['artists'][1:-1].split(',')[0][1:-1], axis=1\n",
    ")\n",
    "\n",
    "df_fill_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_null['first_id_artists'] = df_fill_null.apply(\n",
    "    lambda row: row['id_artists'][1:-1].split(',')[0][1:-1], axis=1\n",
    ")\n",
    "\n",
    "df_fill_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the genre part will go.\n",
    "\n",
    "# # The effective solution:\n",
    "# def get_artist_genres(artist_name):\n",
    "#     # Get track information\n",
    "#     artist_info = sp.search(q=artist_name, type='artist')\n",
    "#     # Extract song name\n",
    "#     genres = artist_info['artists']['items'][0]['genres']\n",
    "\n",
    "#     return genres # As an array\n",
    "\n",
    "# # Sample size:\n",
    "# test = df_fill_null.iloc[1900:1910]\n",
    "# print(get_artist_genres(test['first_artist']))\n",
    "\n",
    "\n",
    "# test['genres'] = test['first_artist'].apply(\n",
    "#     lambda x: get_artist_genres(x)) # Appending each row with its respective genre.\n",
    "# test.iloc[1000]\n",
    "\n",
    "# Here's the issue: Each row takes 0.7 seconds to process. Shorter duration if processed before, and is cached locally.\n",
    "# So far, we have est. 188,000 rows of data.\n",
    "# Thus, it will take a total of 131,600 seconds to fully populate the dataset with genres.\n",
    "# That's 2,193.34 minutes, or 36 and a half hours.\n",
    "\n",
    "# The to-do: reduce time dimensionaltiy, or find an alternative source.\n",
    "\n",
    "# Index 1901 cannot be found on spotify for some reason and is creating issues with obtaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Improved workaround Multi Threading\n",
    "# API Pull function\n",
    "def get_artist_genres(artist_name):\n",
    "    # Get track information\n",
    "    artist_info = sp.search(q=artist_name, type='artist') # API Search\n",
    "    items = artist_info.get('artists', {}).get('items', []) # Specific information pull\n",
    "    # Error checking to ensure that the data structure is as expected before trying to access its elements\n",
    "    # Used to bypass the error from above\n",
    "    if items:\n",
    "        genres = items[0].get('genres', [])\n",
    "        return genres\n",
    "    else:\n",
    "        print(f\"No artist found for {artist_name}\")\n",
    "        return []\n",
    "\n",
    "# Threaded function/service that calls the API Pull function for each row in DataFrame\n",
    "def process_data(data):\n",
    "    # Function to process data\n",
    "    genres_list = []\n",
    "    for artist_name in data['first_artist']:\n",
    "        genres_list.append(get_artist_genres(artist_name))\n",
    "    return genres_list\n",
    "\n",
    "# DataFrame splitting for Parallel Processing (Multi Threading)\n",
    "def split_data(data, num_threads=4):\n",
    "    # Define worker function\n",
    "    def worker(chunk, result, start_index):\n",
    "        for i, artist_name in enumerate(chunk['first_artist']):\n",
    "            result[start_index + i] = get_artist_genres(artist_name)\n",
    "\n",
    "    # Split the data into chunks\n",
    "    chunk_size = len(data) // num_threads\n",
    "    chunks = [data.iloc[i:i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "    # Create threads to process chunks\n",
    "    threads = []\n",
    "    results = [[] for _ in range(len(data))]\n",
    "    for i in range(num_threads):\n",
    "        start_index = i * chunk_size\n",
    "        thread = threading.Thread(target=worker, args=(chunks[i], results, start_index))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage with pandas DataFrame\n",
    "data = df_fill_null.iloc[0:10000]\n",
    "\n",
    "combined_result = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcf88be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukwa\\AppData\\Local\\Temp\\ipykernel_1956\\4180833443.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['genres'] = combined_result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>id_artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song_name_artist</th>\n",
       "      <th>year</th>\n",
       "      <th>first_artist</th>\n",
       "      <th>first_id_artists</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84067</th>\n",
       "      <td>6XAymNI5EF0ZGPYKIyBWZD</td>\n",
       "      <td>Wtf (Ac . Demo 2012)</td>\n",
       "      <td>2</td>\n",
       "      <td>92307</td>\n",
       "      <td>0</td>\n",
       "      <td>['The Jerkwadz']</td>\n",
       "      <td>['2RfzsBVkw2Xw433trjNdcY']</td>\n",
       "      <td>2012-10-22</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.139</td>\n",
       "      <td>63.781</td>\n",
       "      <td>4</td>\n",
       "      <td>Wtf (Ac . Demo 2012)['The Jerkwadz']</td>\n",
       "      <td>2012</td>\n",
       "      <td>The Jerkwadz</td>\n",
       "      <td>2RfzsBVkw2Xw433trjNdcY</td>\n",
       "      <td>[idaho indie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84068</th>\n",
       "      <td>5Ve4qBYAThGLTOva0hhoTa</td>\n",
       "      <td>So Bad</td>\n",
       "      <td>59</td>\n",
       "      <td>325347</td>\n",
       "      <td>1</td>\n",
       "      <td>['Eminem']</td>\n",
       "      <td>['7dGJo4pcD2V6oG8kP0tJRR']</td>\n",
       "      <td>2010-06-18</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.774</td>\n",
       "      <td>81.037</td>\n",
       "      <td>4</td>\n",
       "      <td>So Bad['Eminem']</td>\n",
       "      <td>2010</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>7dGJo4pcD2V6oG8kP0tJRR</td>\n",
       "      <td>[detroit hip hop, hip hop, rap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84069</th>\n",
       "      <td>1pajT8BMXMlABtfZ22fdfO</td>\n",
       "      <td>Your Rules</td>\n",
       "      <td>0</td>\n",
       "      <td>457024</td>\n",
       "      <td>0</td>\n",
       "      <td>['Allan Shee']</td>\n",
       "      <td>['1j5Lb42MRG0K4vmugWuSRs']</td>\n",
       "      <td>2010-12-15</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.760</td>\n",
       "      <td>126.000</td>\n",
       "      <td>4</td>\n",
       "      <td>Your Rules['Allan Shee']</td>\n",
       "      <td>2010</td>\n",
       "      <td>Allan Shee</td>\n",
       "      <td>1j5Lb42MRG0K4vmugWuSRs</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84070</th>\n",
       "      <td>2GJpeySaB1z6mJDEASkIJ4</td>\n",
       "      <td>Ella</td>\n",
       "      <td>59</td>\n",
       "      <td>227867</td>\n",
       "      <td>0</td>\n",
       "      <td>['Tan Bionica']</td>\n",
       "      <td>['37MCoi4pcUf9EKsPXeuCqU']</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>124.979</td>\n",
       "      <td>4</td>\n",
       "      <td>Ella['Tan Bionica']</td>\n",
       "      <td>2010</td>\n",
       "      <td>Tan Bionica</td>\n",
       "      <td>37MCoi4pcUf9EKsPXeuCqU</td>\n",
       "      <td>[argentine rock, argentine telepop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84071</th>\n",
       "      <td>268PcYu5i5f1egp4mQcr4K</td>\n",
       "      <td>The Hitchhiker</td>\n",
       "      <td>0</td>\n",
       "      <td>455158</td>\n",
       "      <td>0</td>\n",
       "      <td>['Allan Shee']</td>\n",
       "      <td>['1j5Lb42MRG0K4vmugWuSRs']</td>\n",
       "      <td>2010-12-15</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.390</td>\n",
       "      <td>125.007</td>\n",
       "      <td>4</td>\n",
       "      <td>The Hitchhiker['Allan Shee']</td>\n",
       "      <td>2010</td>\n",
       "      <td>Allan Shee</td>\n",
       "      <td>1j5Lb42MRG0K4vmugWuSRs</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id                  name  popularity  duration_ms  \\\n",
       "84067  6XAymNI5EF0ZGPYKIyBWZD  Wtf (Ac . Demo 2012)           2        92307   \n",
       "84068  5Ve4qBYAThGLTOva0hhoTa                So Bad          59       325347   \n",
       "84069  1pajT8BMXMlABtfZ22fdfO            Your Rules           0       457024   \n",
       "84070  2GJpeySaB1z6mJDEASkIJ4                  Ella          59       227867   \n",
       "84071  268PcYu5i5f1egp4mQcr4K        The Hitchhiker           0       455158   \n",
       "\n",
       "       explicit           artists                  id_artists release_date  \\\n",
       "84067         0  ['The Jerkwadz']  ['2RfzsBVkw2Xw433trjNdcY']   2012-10-22   \n",
       "84068         1        ['Eminem']  ['7dGJo4pcD2V6oG8kP0tJRR']   2010-06-18   \n",
       "84069         0    ['Allan Shee']  ['1j5Lb42MRG0K4vmugWuSRs']   2010-12-15   \n",
       "84070         0   ['Tan Bionica']  ['37MCoi4pcUf9EKsPXeuCqU']   2010-01-01   \n",
       "84071         0    ['Allan Shee']  ['1j5Lb42MRG0K4vmugWuSRs']   2010-12-15   \n",
       "\n",
       "       danceability  energy  ...  instrumentalness  liveness  valence  \\\n",
       "84067         0.543   0.155  ...          0.000012    0.1220    0.139   \n",
       "84068         0.773   0.811  ...          0.000000    0.1740    0.774   \n",
       "84069         0.796   0.821  ...          0.920000    0.0801    0.760   \n",
       "84070         0.632   0.738  ...          0.000174    0.1200    0.800   \n",
       "84071         0.789   0.928  ...          0.911000    0.1280    0.390   \n",
       "\n",
       "         tempo  time_signature                      song_name_artist  year  \\\n",
       "84067   63.781               4  Wtf (Ac . Demo 2012)['The Jerkwadz']  2012   \n",
       "84068   81.037               4                      So Bad['Eminem']  2010   \n",
       "84069  126.000               4              Your Rules['Allan Shee']  2010   \n",
       "84070  124.979               4                   Ella['Tan Bionica']  2010   \n",
       "84071  125.007               4          The Hitchhiker['Allan Shee']  2010   \n",
       "\n",
       "       first_artist        first_id_artists  \\\n",
       "84067  The Jerkwadz  2RfzsBVkw2Xw433trjNdcY   \n",
       "84068        Eminem  7dGJo4pcD2V6oG8kP0tJRR   \n",
       "84069    Allan Shee  1j5Lb42MRG0K4vmugWuSRs   \n",
       "84070   Tan Bionica  37MCoi4pcUf9EKsPXeuCqU   \n",
       "84071    Allan Shee  1j5Lb42MRG0K4vmugWuSRs   \n",
       "\n",
       "                                    genres  \n",
       "84067                        [idaho indie]  \n",
       "84068      [detroit hip hop, hip hop, rap]  \n",
       "84069                                   []  \n",
       "84070  [argentine rock, argentine telepop]  \n",
       "84071                                   []  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appends the genre list generated as a 'genre' column in the DataFrame\n",
    "data['genres'] = combined_result\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ecab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows without song name.\n",
    "df_removed = df_fill_null.dropna()\n",
    "df_removed.isnull().sum()\n",
    "df_removed.count()\n",
    "# df_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting release_date feature to datetime format, and extracting the year.\n",
    "# df_removed['release_date_datetime'] = pd.to_datetime(df_removed['release_date'], errors='coerce')\n",
    "# df_removed[\"year\"] = df_removed[\"release_date_datetime\"].dt.year\n",
    "# df_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c946e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Spotify API to search for a song's information based on input and adding the necessary information in a DataFrame.\n",
    "def search_track(track_name):\n",
    "    # Search for the track\n",
    "    results = sp.search(q=track_name, type='track')\n",
    "\n",
    "    # Check if the track exists\n",
    "    if results['tracks']['total'] > 0:\n",
    "        # Get the first track from the results\n",
    "        track = results['tracks']['items'][0]\n",
    "        explicit = int(track[\"explicit\"] == True)\n",
    "        print(f'Found track: {track[\"name\"]} by {track[\"artists\"][0][\"name\"]} from the album {track[\"album\"][\"name\"]}.')\n",
    "        track_dict = {\"id\": track[\"id\"], \"name\": track[\"name\"], \"popularity\": track[\"popularity\"], \n",
    "                      \"duration_ms\": track[\"duration_ms\"], \"explicit\": explicit, \"artists\": track[\"artists\"][0][\"name\"],\n",
    "                      \"id_artists\": track[\"artists\"][0][\"id\"], \"release_date\": track[\"album\"][\"release_date\"]}\n",
    "        return track_dict\n",
    "    else:\n",
    "        print('Track not found')\n",
    "        return None\n",
    "\n",
    "# Creating a Single Row DataFrame for the input song.\n",
    "track_result = search_track(input)\n",
    "td = pd.DataFrame(track_result, index=[0])\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Feature Data from song based on its song_id from previous function and adding them to a DataFrame.\n",
    "def get_audio_features(track_result):\n",
    "    song_id = track_result[\"id\"]\n",
    "    results = sp.audio_features(song_id)\n",
    "\n",
    "    if results:\n",
    "        return results[0]\n",
    "    else:\n",
    "        print(f'No audio features found for song ID: {song_id}')\n",
    "        return None\n",
    "\n",
    "audio_features = get_audio_features(track_result)\n",
    "af = pd.DataFrame(audio_features, index=[0])\n",
    "# Taking out the irrevelant features.\n",
    "af_formatted = af.drop([\"type\", \"id\", \"uri\", \"track_href\", \"analysis_url\", \"duration_ms\"], axis=1)\n",
    "# Merging both DataFrames to sync up with the dataset's layout.\n",
    "td = pd.concat([td, af_formatted], axis=1)\n",
    "td['year'] = td['release_date'].str.extract(r'(\\d{4})').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Input Song to the Dataset DataFrame. Added to the very front.\n",
    "new_df = pd.concat([td, df_removed], ignore_index=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalibrating the Index.\n",
    "# new_df = new_df.reset_index(drop=True)\n",
    "# new_df.head()\n",
    "\n",
    "# Checking loudness values.\n",
    "new_df[\"loudness\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf16269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Feature selection, removing non-useful rows.\n",
    "def processing(new_df):\n",
    "    df2 = new_df.drop(['id', 'name', 'id_artists', 'release_date', 'popularity', 'mode', \"song_name_artist\"], axis=1)\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    numerical_features = ['duration_ms', 'loudness', 'tempo']\n",
    "    scaler = MinMaxScaler()\n",
    "    df2[numerical_features] = scaler.fit_transform(df2[numerical_features])\n",
    "    \n",
    "    # Standardise Year\n",
    "    df2['standardized_year'] = scaler.fit_transform(df2[['year']])\n",
    "    df2 = df2.drop(['year'], axis=1)\n",
    "\n",
    "    # Create a feature matrix\n",
    "    feature_matrix = df2.drop(['artists'], axis=1)\n",
    "    # This is the input song. We are isolating it from the dataframe first.\n",
    "    input = feature_matrix.iloc[0].T\n",
    "    # This is the rest of the songs.\n",
    "    feature_matrix = feature_matrix.iloc[1:]\n",
    "\n",
    "    # Apply cosine similarity\n",
    "    start = 0\n",
    "    end = 1000\n",
    "    arr = []\n",
    "    \n",
    "    # Returns comparison value of first song in dataset to all others in an array.\n",
    "    # DataFrame can be customised before Feature Selection to change which song the subject of comparison should be.\n",
    "    while end < feature_matrix['explicit'].count():\n",
    "        # Compile the nth 1,000 songs in the dataframe.\n",
    "        set = feature_matrix.iloc[start:end].T\n",
    "        # Add the input song to the top of the dataframe.\n",
    "        compare_df = pd.concat([input, set], axis=1).T\n",
    "        # Perform cosine similarity.\n",
    "        cosine_sim = cosine_similarity(compare_df) # Comparing bit by bit to prevent too many dimensions.\n",
    "        cs_list = cosine_sim[0].tolist() # Taking only the first row a.k.a the comparison between the first song and all others.\n",
    "        arr += cs_list\n",
    "        # Prepare for the next 1,000 songs.\n",
    "        start = end\n",
    "        end += 1000\n",
    "    return arr\n",
    "arr = processing(new_df)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(arr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb86690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_suggestions(arr):\n",
    "    suggestions = []\n",
    "    \n",
    "    # Compiling all song ids that are above the pre-determined threshold for 'like the first song'.\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] > 0.995:\n",
    "            suggestions.append(i)\n",
    "    \n",
    "    print(suggestions)\n",
    "    return suggestions\n",
    "suggestions = compile_suggestions(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3595884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting out the end result information.\n",
    "def format_suggestions(suggestions):\n",
    "    # first = suggestions[1]\n",
    "\n",
    "    # Creating the new dataframe with the first matched song.\n",
    "#     main = df_removed.iloc[suggestions].copy()\n",
    "#     df_main = pd.DataFrame(main)\n",
    "#     df_main = df_main.T\n",
    "#    print(df_removed.tail())\n",
    "    df_main = new_df.loc[suggestions]\n",
    "\n",
    "    # Adding the rest of the matched songs to the dataframe.\n",
    "#     for n in range (2, len(suggestions)):\n",
    "#         temp = df_removed.iloc[suggestions[n],:6].copy()\n",
    "#         df_temp = pd.DataFrame(temp)\n",
    "#         df_temp = df_temp.T\n",
    "#         df_main = pd.concat([df_main, df_temp])\n",
    "\n",
    "#     df_main = df_main.drop(['popularity', 'duration_ms', 'explicit'], axis=1)\n",
    "    return df_main\n",
    "\n",
    "df_main = format_suggestions(suggestions).iloc[1:]\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789dc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising and Weighting Years.\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# def weighting(df_main): \n",
    "#     df_main['year'] = pd.to_numeric(df_main['year'])\n",
    "#     scaler = StandardScaler()\n",
    "#     df_main['standardized_year'] = scaler.fit_transform(df_main[['year']])\n",
    "#     year_compare = df_main['standardized_year'].loc[0]\n",
    "#     df_main = df_main.drop\n",
    "#     return df_main\n",
    "# df_final = weighting(df_main)\n",
    "# df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1190d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.count() # There is one less for the last 3 features as the input song did not go through the extracted year's steps.\n",
    "# df_final['standardized_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generating 10 of the matched songs at random.\n",
    "def recommend(df_main):\n",
    "    print('Here are your recommendations!')\n",
    "    for c in range(10):\n",
    "        recc = df_main.sample().to_dict()\n",
    "        name = list(recc['name'].values())[0]\n",
    "        artists = (list(recc['artists'].values())[0])[1:len(list(recc['artists'].values())[0])-1]\n",
    "        year = str(list(recc['year'].values())[0])\n",
    "        print(str(c + 1) + '. ' + name + ' by ' + artists + 'published in ' + year)\n",
    "        df_main = df_main.drop(list(recc['id'])[0])\n",
    "    \n",
    "# May want to try a filter for repreventing duplicate songs in the list.\n",
    "recommend(df_main) # End Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(new_df[\"year\"])\n",
    "\n",
    "# To do:\n",
    "# Artist Genre and Langauge of Artist to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyOAuth\n",
    "# from flask import Flask, url_for, session, request, redirect\n",
    "# import json\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from .downloadvideos import DownloadVideosFromTitles\n",
    "\n",
    "# # App config\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# app.secret_key = 'SOMETHING-RANDOM'\n",
    "# app.config['SESSION_COOKIE_NAME'] = 'spotify-login-session'\n",
    "\n",
    "# @app.route('/')\n",
    "# def login():\n",
    "#     sp_oauth = create_spotify_oauth()\n",
    "#     auth_url = sp_oauth.get_authorize_url()\n",
    "#     print(auth_url)\n",
    "#     return redirect(auth_url)\n",
    "\n",
    "# @app.route('/authorize')\n",
    "# def authorize():\n",
    "#     sp_oauth = create_spotify_oauth()\n",
    "#     session.clear()\n",
    "#     code = request.args.get('code')\n",
    "#     token_info = sp_oauth.get_access_token(code)\n",
    "#     session[\"token_info\"] = token_info\n",
    "#     return redirect(\"/getTracks\")\n",
    "\n",
    "# @app.route('/logout')\n",
    "# def logout():\n",
    "#     for key in list(session.keys()):\n",
    "#         session.pop(key)\n",
    "#     return redirect('/')\n",
    "\n",
    "# @app.route('/getTracks')\n",
    "# def get_all_tracks():\n",
    "#     session['token_info'], authorized = get_token()\n",
    "#     session.modified = True\n",
    "#     if not authorized:\n",
    "#         return redirect('/')\n",
    "#     sp = spotipy.Spotify(auth=session.get('token_info').get('access_token'))\n",
    "#     results = []\n",
    "#     iter = 0\n",
    "#     while True:\n",
    "#         offset = iter * 50\n",
    "#         iter += 1\n",
    "#         curGroup = sp.current_user_saved_tracks(limit=50, offset=offset)['items']\n",
    "#         for idx, item in enumerate(curGroup):\n",
    "#             track = item['track']\n",
    "#             val = track['name'] + \" - \" + track['artists'][0]['name']\n",
    "#             results += [val]\n",
    "#         if (len(curGroup) < 50):\n",
    "#             break\n",
    "    \n",
    "#     df = pd.DataFrame(results, columns=[\"song names\"]) \n",
    "#     df.to_csv('songs.csv', index=False)\n",
    "#     return \"done\"\n",
    "\n",
    "\n",
    "# # Checks to see if token is valid and gets a new token if not\n",
    "# def get_token():\n",
    "#     token_valid = False\n",
    "#     token_info = session.get(\"token_info\", {})\n",
    "\n",
    "#     # Checking if the session already has a token stored\n",
    "#     if not (session.get('token_info', False)):\n",
    "#         token_valid = False\n",
    "#         return token_info, token_valid\n",
    "\n",
    "#     # Checking if token has expired\n",
    "#     now = int(time.time())\n",
    "#     is_token_expired = session.get('token_info').get('expires_at') - now < 60\n",
    "\n",
    "#     # Refreshing token if it has expired\n",
    "#     if (is_token_expired):\n",
    "#         sp_oauth = create_spotify_oauth()\n",
    "#         token_info = sp_oauth.refresh_access_token(session.get('token_info').get('refresh_token'))\n",
    "\n",
    "#     token_valid = True\n",
    "#     return token_info, token_valid\n",
    "\n",
    "\n",
    "# def create_spotify_oauth():\n",
    "#     return SpotifyOAuth(\n",
    "#             client_id=\"id\",\n",
    "#             client_secret=\"secret\",\n",
    "#             redirect_uri=url_for('authorize', _external=True),\n",
    "#             scope=\"user-library-read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c4cc5e",
   "metadata": {},
   "source": [
    "##### client ID and secret for an yu's spotify project \n",
    "client id = 4a5c41a987b64342884ca4d5c090ed84\n",
    "<br>\n",
    "client secret = dbc5f7a16b6b44e990be11cd09dd7374"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
